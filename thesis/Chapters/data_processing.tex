%*******************************************************
% Data acquisition and processing
%*******************************************************
% \pdfbookmark[0]{Data Acquisition and Processing}{data_processing}
%\lhead{\emph{Data Acquisition}}

\chapter{Data Acquisition and Processing}

\section{Data Acquisition}

The domain is chosen so that enough stations are available from the continents that surround Antarctica.
It is centred at the South Pole and extends 115$^\circ$ in North-South direction and 110$^\circ$ in
East-West direction. 
For the selection of the earthquakes the built-in LASIF feature \
add\_gcmt\_events is used to select 50 events equally distributed in the
domain. %(see \autoref{eqmap}). 
Nearly six gigabyte of waveform data are acquired this way.
The earthquakes cover a range of Moment Magnitudes between 5.2 and 6.3 (\autoref{depth_scatter}). 
With 48 out of 50 most earthquakes having a depth smaller than 50\,km. Among these most 
events are much shallower than 50\,km. Only two events are in a depth range of 150 to 200\,km. 
No larger events are chosen as the point source approximation would not hold otherwise. 
The events are relatively equally distributed between 2005 and 2014 (\autoref{temp_dist}). 
No events before 2005 are used as the instrumentation before then was very scarce on Antarctica. 
\autoref{event_data} shows that on average more waveforms are available for the more recent earthquakes.
The coverage of the Antarctic continent by the selected data is visualised with a raydensity plot (\autoref{raydens}) 
that connects all stations with the recorded earthquakes. It can clearly be seen that the highest aggregation of stations 
exists in New Zealand. The reason therefore is the high seismic risk due to the proximity of the New Zealand population to tectonic plate boundaries (Alpine Fault and Kermadec Trench). \\


%\begin{figure}[H]
%\begin{center}
%\includegraphics[width = 0.85\textwidth]{images/eqmap.png}
%\caption{The red lines indicate the borders of the domain. The size of the ellipsoids depend on the magnitude of each event.}
%\label{eqmap}
%\end{center}
%\end{figure}

%\begin{figure}[H]
%\begin{center}
%\includegraphics[width = 1\textwidth]{images/magnitude_hist.eps}
%\caption{Moment magnitudes range from 5.2 to 6.3, while most events are smaller than 5.6.}
%\label{mag_dist}
%\end{center}
%\end{figure}

\begin{figure}[h]
\begin{center}
\includegraphics[width = 1\textwidth]{images/temporal_distribution_2.eps}
\caption[Temporal distribution of the earthquakes.]
{The histogram shows the number of earthquakes that were used from every year between 2005 and 2014.
The distribution of events is spread relatively well over the years.}
%{The earthquakes are equally spread over 
% interval from 2005 to 2014.}
\label{temp_dist}
\end{center}
\end{figure}

\begin{figure}[h]
\begin{center}
\includegraphics[width = 1\textwidth]{images/magnitude_vs_depth.png}
\caption[Depth distribution of the earthquakes.]{The earthquakes cluster between 10 and 20\,km, 
2 are between 150 and 200\,km. 
Histograms show the distribution of Moment Magnitude (right side) and depths (top).}
\label{depth_scatter}
\end{center}
\end{figure}

% PRELIMINARY PLOT FOR EVENT DATA
\begin{figure}[h]
\begin{center}
\includegraphics[width = 1\textwidth]{images/event_data_barchart_sorted_by_origin_time.png}
\caption[Raw seismograms per event]{Events sorted by origin time (from top to bottom) with the amount 
of acquired raw seismograms per event.}
\label{event_data}
\end{center}
\end{figure}

%\begin{figure}[H]
%\begin{center}
%\includegraphics[height = 0.95\textheight]{images/depth_histogram.eps}
%\caption{The earthquakes cluster between 10 and 20\,km, 2 are between 150 and 200\,km (not shown on this plot).}
%\label{depth_dist}
%\end{center}
%\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[width = 1\textwidth]{images/raydensity_no_title.png}
\caption[The raydensity plot for the 50 events.]{The raydensity plot connects all stations (triangles) with the 50 
events (beachballs) for which waveforms exist. 
The 593 stations do not have data for every earthquake, as some events are far away so that the events cannot be well
distinguished from the instrument noise. In total there are more than 9500 ray paths.}
\label{raydens}
\end{center}
\end{figure}

As the station from the Global Seismographic Network (GSN) are the most important ones due to their high standards on used 
instruments and continuous recording, it is made sure that all available waveforms can be used in the LASIF project. 
Therefore data missing from the LASIF download is acquired from IRIS via an obspy fdsn client \citep{Krischer2015}. 
The waveform data is then horizontally correct rotated and StationXML files are downloaded from the IRIS website to
ensure the availability of instrumentation metadata for all required time intervals. \\

%After the data is collected it is checked if station information is available for each waveform, if duplicates exist, if 
%waveforms are corrupted and all raypaths from station to event location are within the domain. 
%If the last check fails an automatic script from LASIF is created to delete the violating raypaths. 
%When all the checks pass the waveforms can be preprocessed. 

After the collection of data the following checks are performed:
\begin{itemize}
\item Is station information for every waveform available?
\item Do duplicate waveforms exist?
\item Are waveform data files corrupted?
\item Are all waveforms within the LASIF domain?
\end{itemize}

Waveforms that do not pass the checks can be directly deleted with automatically created script.
After the checks all seismograms can be processed. 


%\lhead{\emph{Data Processing}}

\section{Data Processing}

The real waveform data and the simulated ones have to be processed as similarly as possible to avoid misfits only due
to different data manipulation. 
The preprocessing of the observed data starts with the creation of a new iteration for which the frequency band and 
the seismic solver is selected.
For all the iterations SPECFEM3D GLOBE CEM is selected as solver and a period band between 60 to 120 seconds is chosen.
Following iterations would then also include higher frequencies.

%\begin{table}[h]
%\begin{center}
%\begin{tabular}{{l|ccc}}
%Iteration number  &1    			&2 				&3 \\
%\hline
%Frequency band    &60-120\,seconds	&40-70\,seconds	&60-120\,seconds          \\
%\end{tabular}
%\end{center}
%\end{table}

Hereby the larger value for the period indicates the corner frequency for the highpass filter and the lower value the 
corner frequency for the lowpass filter. Hence the preprocessing can be understood as the application of a bandpass filter. 
Filtering is required not just to remove noise, but also to make the data comparable to the later created synthetic waveforms.
To make the following instrument response faster the sampling rate is downsampled from 20 to 10$\,$Hz.
Any linear trends in the data are removed and the mean of the data is set to zero.
%
As every seismic instrument has its own characteristics these have to be removed to make the different observed seismograms 
comparable within each other and to the synthetic seismograms.
%
Furthermore it is necessary that the original and synthetic datasets have the same length, therefore the seismogram is trimmed in case 
the observation period is too long or interpolated too make the number of data points in both files equal. 
For the adjoint method in SPECFEM displacement seismograms are needed and therefore all data has to be converted to 
displacement data as some seismograms were given as velocity data.

After the simulations are finished also the synthetic seismograms have to be adapted to a common sampling rate and 
they have to cover the same time interval as the observed data.
Furthermore the standard procedures demean and detrend are applied.
% Convolution with source time function








